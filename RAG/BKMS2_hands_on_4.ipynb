{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpZzVbHW0vNn"
      },
      "source": [
        "# BKMS2 Hands-on #4: Developing a Q&A system based on RAG"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLNqwI6ZDJqT"
      },
      "source": [
        "### Colab Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l85nD1ixD9cm"
      },
      "outputs": [],
      "source": [
        "!unzip /content/data.zip -d /content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "AeUZW9p5wwzK"
      },
      "outputs": [],
      "source": [
        "!pip install -r /content/data/requirements.txt # > /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Flr9JgnUBN6k"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQ3pGqkwCeyr"
      },
      "source": [
        "## 1. Basic Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_k1PtjoAIbo4"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "import chromadb\n",
        "import chromadb.utils.embedding_functions as embedding_functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "20JIfbZYt0so"
      },
      "outputs": [],
      "source": [
        "from getpass import getpass\n",
        "\n",
        "OPENAI_API_KEY = getpass(\"Please enter your OpenAI API key: \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tptQdnB2GLUD"
      },
      "outputs": [],
      "source": [
        "# from dotenv import load_dotenv\n",
        "# import os, warnings\n",
        "\n",
        "# load_dotenv('./data/.env')\n",
        "# OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
        "# warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-Zjag3l0ulT"
      },
      "source": [
        "### 1-1. Load and Split the Document"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zl4LZuvMs0Mu"
      },
      "outputs": [],
      "source": [
        "def loadText(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        text = file.read()\n",
        "    return text\n",
        "\n",
        "\n",
        "def splitText(text, chunk_size, overlap_size):\n",
        "    chunks = []\n",
        "    start = 0\n",
        "\n",
        "    while start < len(text):\n",
        "        end = min(start + chunk_size, len(text))\n",
        "        chunks.append(text[start:end])\n",
        "\n",
        "        start += chunk_size - overlap_size\n",
        "\n",
        "    return chunks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akTNvXa_2e17"
      },
      "source": [
        "### 1-2. Store in a Vector Database"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WW25Fp1T0uC2"
      },
      "outputs": [],
      "source": [
        "file_path = \"./data/2024학년도 2학기 데이터사이언스대학원 석사학위 논문심사 계획 공고.txt\"\n",
        "document = loadText(file_path)\n",
        "\n",
        "# Split the text into overlapping chunks\n",
        "chunks = splitText(document, chunk_size=300, overlap_size=50)\n",
        "\n",
        "print(len(chunks))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yQSzdEnQ4BT2"
      },
      "outputs": [],
      "source": [
        "# Initialize ChromaDB client\n",
        "client = chromadb.PersistentClient(path=\"./vectordb/\")\n",
        "\n",
        "# Setup the collection to store embeddings\n",
        "openai_ef = embedding_functions.OpenAIEmbeddingFunction(\n",
        "            api_key=OPENAI_API_KEY,\n",
        "            model_name=\"text-embedding-3-small\"\n",
        "        )\n",
        "\n",
        "collection = client.get_or_create_collection(\"gsds\", embedding_function=openai_ef)\n",
        "\n",
        "# Add documents and embeddings to ChromaDB collection\n",
        "collection.add(\n",
        "    ids=[f\"chunk_{i}\" for i in range(len(chunks))],\n",
        "    documents=chunks,\n",
        "    metadatas=[{\"reference\": file_path.split('/')[-1]} for i in range(len(chunks))]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eCAFDQXZtkPH"
      },
      "outputs": [],
      "source": [
        "# client.delete_collection(\"gsds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogSPTlMb2qYH"
      },
      "source": [
        "### 1-3. Retrieval, Augmentation and Generation (RAG)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pz6RCONdychD"
      },
      "outputs": [],
      "source": [
        "# Example query\n",
        "# query = input('Question:')\n",
        "query = \"학위 논문 제출 기한은 언제까지인가요?\"\n",
        "\n",
        "# Retrieve top 3 relevant passages\n",
        "results = collection.query(\n",
        "    query_texts=query,\n",
        "    n_results=3\n",
        ")\n",
        "\n",
        "# Format the retrieved passages\n",
        "passages = \"\\n\".join([f\"Passage {i} (data_source: {meta['reference']}):\\n{doc.strip()}\\n\" for i, (doc, meta) in enumerate(zip(results['documents'][0], results['metadatas'][0]), 1)])\n",
        "\n",
        "# Create a more structured prompt\n",
        "prompt = f\"\"\"\n",
        "# Question: {query}\n",
        "\n",
        "# Relevant Passages:\n",
        "{passages}\n",
        "\n",
        "# Based on the passages above, generate an answer to the question. Explicitly mention the 'data_source'.\n",
        "ex) (출처: gsds_notification.pdf)\n",
        "\"\"\"\n",
        "\n",
        "# print(prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2rn8sVGatq5m"
      },
      "outputs": [],
      "source": [
        "results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ndzf-B7U4aw8"
      },
      "outputs": [],
      "source": [
        "llm = OpenAI(api_key=OPENAI_API_KEY)\n",
        "\n",
        "response = llm.chat.completions.create(\n",
        "        model='gpt-4o-mini',\n",
        "        messages=[\n",
        "            {\"role\": \"user\", \"content\": prompt},\n",
        "        ],\n",
        "        temperature=0\n",
        "    )\n",
        "\n",
        "print('Answer:', response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tlmPaOGUunGP"
      },
      "source": [
        "### 1-4. Various Distance Metrics for Semantic Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p4D3mMLts0Pq"
      },
      "outputs": [],
      "source": [
        "distance_metric = [\"l2\", \"cosine\", \"ip\"] # default: l2\n",
        "query = \"학위 논문 제출 기한은 언제까지인가요?\"\n",
        "\n",
        "for metric in distance_metric:\n",
        "  collection = client.get_or_create_collection(\n",
        "      name=f\"gsds-{metric}\",\n",
        "      embedding_function=openai_ef,\n",
        "      metadata={\"hnsw:space\": metric}\n",
        "      )\n",
        "\n",
        "  collection.add(\n",
        "    ids=[f\"chunk_{i}\" for i in range(len(chunks))],\n",
        "    documents=chunks,\n",
        "    metadatas=[{\"reference\": file_path.split('/')[-1]} for i in range(len(chunks))]\n",
        "    )\n",
        "\n",
        "  results = collection.query(\n",
        "    query_texts=query,\n",
        "    n_results=3\n",
        "    )\n",
        "\n",
        "  client.delete_collection(f\"gsds-{metric}\")\n",
        "\n",
        "  print(f'{metric}:', results['ids'][0], results['distances'][0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zb7M7u5htXbu"
      },
      "source": [
        "## 2. Implementing RAG With Langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bncAfe6eU6_r"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
        "from langchain_chroma import Chroma\n",
        "\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "from langchain_core.vectorstores import InMemoryVectorStore\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.documents import Document\n",
        "\n",
        "from langchain_community.document_loaders import TextLoader, PyPDFLoader, AsyncHtmlLoader\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain_community.document_transformers import Html2TextTransformer\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "import io"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t62bkYPyqZae"
      },
      "source": [
        "### 2-1. Load and Store the data from `URL`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aktC5G5-ucrp"
      },
      "outputs": [],
      "source": [
        "urls = [\"https://gsds.snu.ac.kr/academics/recruitment/\"]\n",
        "html = AsyncHtmlLoader(urls).load()\n",
        "\n",
        "html2text = Html2TextTransformer()\n",
        "\n",
        "docs_transformed = html2text.transform_documents(html)\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=60)\n",
        "docs_html = text_splitter.split_documents(docs_transformed)\n",
        "\n",
        "vector_store = Chroma.from_documents(docs_html, OpenAIEmbeddings(model='text-embedding-3-large', openai_api_key=OPENAI_API_KEY))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDrUaPpSqhLR"
      },
      "source": [
        "### 2-2. Load and Store the data from `.txt` / `.pdf`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "mTIkVnrQkSdn"
      },
      "outputs": [],
      "source": [
        "documents = TextLoader(\"./data/2024학년도 2학기 데이터사이언스대학원 석사학위 논문심사 계획 공고.txt\").load()\n",
        "# documents = PyPDFLoader(\"./data/2024학년도 2학기 데이터사이언스대학원 석사학위 논문심사 계획 공고.pdf\").load()\n",
        "\n",
        "docs = text_splitter.split_documents(documents)\n",
        "\n",
        "vector_store.add_documents(documents = docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wSH6sGLhh-us"
      },
      "outputs": [],
      "source": [
        "# vector_store.delete_collection()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_H912xibqqVG"
      },
      "source": [
        "### 2-3. Retrieval, Augmentation and Generation (RAG)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y8c9lN6uiSJX"
      },
      "outputs": [],
      "source": [
        "# query = input('Question: ')\n",
        "query = '박사 과정 신입학 모집 인원은 몇 명이야?'\n",
        "retrieved_docs = vector_store.similarity_search(query, k=3)\n",
        "\n",
        "passages = \"\\n\".join([f\"Passage {i+1} (data_source: {doc.metadata['source']}):\\n{doc.page_content}\\n\" for i, doc in enumerate(retrieved_docs)])\n",
        "\n",
        "prompt_template = f\"\"\"\n",
        "# Question: {query}\n",
        "\n",
        "# Relevant Passages:\n",
        "{passages}\n",
        "\n",
        "# Based on the passages above, generate an answer to the question. Explicitly mention the 'data_source'.\n",
        "ex) (출처: gsds_notification.pdf)\n",
        "\"\"\"\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0, openai_api_key=OPENAI_API_KEY)\n",
        "prompt = PromptTemplate(template=prompt_template, input_variables=[\"query\", \"passages\"])\n",
        "\n",
        "chain = prompt | llm\n",
        "response = chain.invoke({\"query\": query, \"passages\": passages})\n",
        "\n",
        "print('Answer:', response.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-0z47IZvA8O"
      },
      "source": [
        "### 2-4. Run the RAG Chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RiE37O3XYW9K"
      },
      "outputs": [],
      "source": [
        "def execute_chain():\n",
        "  print(\"Type 'exit' to quit\")\n",
        "  while True:\n",
        "    query = input(\"Enter a prompt: \")\n",
        "    if query.lower() == 'exit':\n",
        "      print('Exiting...')\n",
        "      break\n",
        "\n",
        "    else:\n",
        "      retrieved_docs = vector_store.similarity_search(query, k=5)\n",
        "      passages = \"\\n\".join([f\"Passage {i} (data_source: {doc.metadata['source']}):\\n{doc.page_content}\\n\" for i, doc in enumerate(retrieved_docs)])\n",
        "      prompt_template = f\"\"\"\n",
        "# Question: {query}\n",
        "\n",
        "# Relevant Passages:\n",
        "{passages}\n",
        "\n",
        "# Based on the passages above, generate an answer to the question. Explicitly mention the 'data_source'.\n",
        "ex) (출처: gsds_notification.pdf)\n",
        "\"\"\"\n",
        "      try:\n",
        "        llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0, openai_api_key=OPENAI_API_KEY)\n",
        "        prompt = PromptTemplate(template=prompt_template, input_variables=[\"query\", \"passages\"])\n",
        "        chain = prompt | llm\n",
        "        response = chain.invoke({\"query\": query, \"passages\": passages})\n",
        "        print('Answer:', response.content)\n",
        "\n",
        "      except Exception as e:\n",
        "          print(e)\n",
        "\n",
        "execute_chain()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
