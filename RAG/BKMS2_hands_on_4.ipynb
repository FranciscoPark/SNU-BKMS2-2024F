{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpZzVbHW0vNn"
      },
      "source": [
        "# BKMS2 Hands-on #4: Developing a Q&A system based on RAG"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLNqwI6ZDJqT"
      },
      "source": [
        "### Colab Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!unzip /content/data.zip -d /content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "collapsed": true,
        "id": "AeUZW9p5wwzK"
      },
      "outputs": [],
      "source": [
        "!pip install -r /content/data/requirements.txt > /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20JIfbZYt0so",
        "outputId": "bacad455-cf1e-451c-ca87-245a6abff6d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please enter your OpenAI API key: ··········\n"
          ]
        }
      ],
      "source": [
        "# from dotenv import load_dotenv\n",
        "# import os, warnings\n",
        "\n",
        "# load_dotenv('./data/.env')\n",
        "# OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
        "# warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from getpass import getpass\n",
        "\n",
        "OPENAI_API_KEY = getpass(\"Please enter your OpenAI API key: \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQ3pGqkwCeyr"
      },
      "source": [
        "## 1. Basic Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "_k1PtjoAIbo4"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "import chromadb\n",
        "import chromadb.utils.embedding_functions as embedding_functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-Zjag3l0ulT"
      },
      "source": [
        "### 1-1. Load and Split the Document"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "Zl4LZuvMs0Mu"
      },
      "outputs": [],
      "source": [
        "def loadText(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        text = file.read()\n",
        "    return text\n",
        "\n",
        "\n",
        "def splitText(text, chunk_size, overlap_size):\n",
        "    chunks = []\n",
        "    start = 0\n",
        "\n",
        "    while start < len(text):\n",
        "        end = min(start + chunk_size, len(text))\n",
        "        chunks.append(text[start:end])\n",
        "\n",
        "        start += chunk_size - overlap_size\n",
        "\n",
        "    return chunks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akTNvXa_2e17"
      },
      "source": [
        "### 1-2. Store in a Vector Database"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "eCAFDQXZtkPH"
      },
      "outputs": [],
      "source": [
        "# client.delete_collection(\"gsds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WW25Fp1T0uC2",
        "outputId": "d065be11-1534-4919-c815-110d344144d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "17\n"
          ]
        }
      ],
      "source": [
        "file_path = \"./data/2024학년도 2학기 데이터사이언스대학원 석사학위 논문심사 계획 공고.txt\"  # Replace with the actual path of your txt file\n",
        "document = loadText(file_path)\n",
        "\n",
        "# Split the text into overlapping chunks\n",
        "chunks = splitText(document, chunk_size=300, overlap_size=50)\n",
        "\n",
        "print(len(chunks))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "yQSzdEnQ4BT2"
      },
      "outputs": [],
      "source": [
        "# Initialize ChromaDB client\n",
        "client = chromadb.PersistentClient(path=\"./vectordb/\")\n",
        "\n",
        "# Setup the collection to store embeddings\n",
        "openai_ef = embedding_functions.OpenAIEmbeddingFunction(\n",
        "            api_key=OPENAI_API_KEY,\n",
        "            model_name=\"text-embedding-3-small\"\n",
        "        )\n",
        "\n",
        "collection = client.get_or_create_collection(\"gsds\", embedding_function=openai_ef)\n",
        "\n",
        "# Add documents and embeddings to ChromaDB collection\n",
        "collection.add(\n",
        "    ids=[f\"chunk_{i}\" for i in range(len(chunks))],\n",
        "    documents=chunks,\n",
        "    metadatas=[{\"reference\": file_path.split('/')[-1]} for i in range(len(chunks))]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogSPTlMb2qYH"
      },
      "source": [
        "### 1-3. Retrieval, Augmentation and Generation (RAG)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "Pz6RCONdychD"
      },
      "outputs": [],
      "source": [
        "# Example query\n",
        "# query = input('Question:')\n",
        "query = \"학위 논문 제출 기한은 언제까지인가요?\"\n",
        "\n",
        "# Retrieve top 3 relevant passages\n",
        "results = collection.query(\n",
        "    query_texts=query,\n",
        "    n_results=3\n",
        ")\n",
        "\n",
        "# Format the retrieved passages\n",
        "passages = \"\\n\".join([f\"Passage {i} (data_source: {meta['reference']}):\\n{doc.strip()}\\n\" for i, (doc, meta) in enumerate(zip(results['documents'][0], results['metadatas'][0]), 1)])\n",
        "\n",
        "# Create a more structured prompt\n",
        "prompt = f\"\"\"\n",
        "# Question: {query}\n",
        "\n",
        "# Relevant Passages:\n",
        "{passages}\n",
        "\n",
        "# Based on the passages above, generate an answer to the question. Explicitly mention the 'data_source'.\n",
        "ex) (출처: gsds_notification.pdf)\n",
        "\"\"\"\n",
        "# print(prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2rn8sVGatq5m",
        "outputId": "9e1a2370-0b7c-4c41-c9d5-c2abed4228ab"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'ids': [['chunk_7', 'chunk_8', 'chunk_15']],\n",
              " 'distances': [[0.7706437870639522, 0.8314104845748295, 0.8778864412731177]],\n",
              " 'metadatas': [[{'reference': '2024학년도 2학기 데이터사이언스대학원 석사학위 논문심사 계획 공고.txt'},\n",
              "   {'reference': '2024학년도 2학기 데이터사이언스대학원 석사학위 논문심사 계획 공고.txt'},\n",
              "   {'reference': '2024학년도 2학기 데이터사이언스대학원 석사학위 논문심사 계획 공고.txt'}]],\n",
              " 'embeddings': None,\n",
              " 'documents': [['하여 직접 행정실 및 심사 위원께 각각 메일로 제출\\n     - 최종심사 및 구술고사: 2024. 12. 13. (금)\\n     - 종결: 2025. 1. 10.(금)\\n\\n3. 학위논문 제출(미제출시 학위수여 대상에서 제외됨)\\n 가. 학위논문심사에 합격한 자는 정해진 기간 내에 학위논문을 제출해야 함\\n   * 논문 제목은 최종 논문심사요지의 제목과 반드시 일치하여야 함\\n  나. 학위논문 PDF 원문 파일 제출\\n    1) 제출기간 : 2025. 1. 17.(금) ∼ 2. 3.(월) 24:00 <18일간> \\n    2) 책자논문 제출 ',\n",
              "   '1. 17.(금) ∼ 2. 3.(월) 24:00 <18일간> \\n    2) 책자논문 제출 없이 원문파일만 제출 \\n    3) 마감 이후 제출/수정 불가\\n    4) 논문을 제출하지 않을 경우 학위를 받을 수 없음 \\n    5) 논문제출 방법, 학생 안내자료 등은 별도 공지 예정 \\n\\n4. 심사용 논문 작성요령<학위수여규정 제10조>\\n 가. 국문 또는 영문으로 작성함을 원칙으로 하되, 국문초록 및 외국어초록을 반드시 첨부하여야하며 초록 하단에 논문의 주제를 나타낼 수 있는 주요어(Keywords)를 표기하여야함\\n 나. 외국어로 작성된 ',\n",
              "   ' 제출일 : 2023. 12. 26.(화) 까지 석사학위논문심사요지를 행정실에 제출 \\n  - 심사위원장이 심사위원의 의견을 작성하고 심사위원 전원이 날인하여 행정실에 제출\\n2025. 1. 10.(금) \\n종결\\n최종 논문을 지도교수의 확인을 받아 최종 종결\\n2025. 1. 17.(금)\\n∼ 2. 3.(월) 24:00 <18일간> \\n원문파일 제출\\n1. 학위논문심사에 합격한 자는 정해진 기간 내에 학위논문을 제출해야 함\\n * 논문 제목은 최종 논문심사요지의 제목과 반드시 일치하여야 함\\n2. 학위논문 PDF 원문 파일 제출\\n ◦ 책자논문 제출']],\n",
              " 'uris': None,\n",
              " 'data': None,\n",
              " 'included': ['metadatas', 'documents', 'distances']}"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ndzf-B7U4aw8",
        "outputId": "30c24d15-eecc-43d3-9b10-94bdedfa3525"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Answer: 학위 논문 제출 기한은 2025년 1월 17일(금)부터 2월 3일(월) 24:00까지입니다. 이 기간 동안 학위논문 PDF 원문 파일을 제출해야 하며, 제출하지 않을 경우 학위를 받을 수 없습니다. (출처: 2024학년도 2학기 데이터사이언스대학원 석사학위 논문 심사 계획 공고.txt)\n"
          ]
        }
      ],
      "source": [
        "llm = OpenAI(api_key=OPENAI_API_KEY)\n",
        "\n",
        "response = llm.chat.completions.create(\n",
        "        model='gpt-4o-mini',\n",
        "        messages=[\n",
        "            {\"role\": \"user\", \"content\": prompt},\n",
        "        ],\n",
        "        temperature=0\n",
        "    )\n",
        "\n",
        "print('Answer:', response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tlmPaOGUunGP"
      },
      "source": [
        "### 1-4. Various Distance Metrics for Semantic Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4D3mMLts0Pq",
        "outputId": "faf7aa0f-63ee-49eb-ad06-490724841ce0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "l2: ['chunk_7', 'chunk_8', 'chunk_15'] [0.7707362031473365, 0.8313149965094855, 0.8807400922146627]\n",
            "cosine: ['chunk_7', 'chunk_8', 'chunk_15'] [0.38536804035080297, 0.41565745981877245, 0.43931590873398574]\n",
            "ip: ['chunk_7', 'chunk_8', 'chunk_15'] [0.3840508969754728, 0.41503858267255234, 0.4401669916432607]\n"
          ]
        }
      ],
      "source": [
        "distance_metric = [\"l2\", \"cosine\", \"ip\"] # default: l2\n",
        "query = \"학위 논문 제출 기한은 언제까지인가요?\"\n",
        "\n",
        "for metric in distance_metric:\n",
        "  collection = client.get_or_create_collection(\n",
        "      name=f\"gsds-{metric}\",\n",
        "      embedding_function=openai_ef,\n",
        "      metadata={\"hnsw:space\": metric}\n",
        "      )\n",
        "\n",
        "  collection.add(\n",
        "    ids=[f\"chunk_{i}\" for i in range(len(chunks))],\n",
        "    documents=chunks,\n",
        "    metadatas=[{\"reference\": file_path.split('/')[-1]} for i in range(len(chunks))]\n",
        "    )\n",
        "\n",
        "  results = collection.query(\n",
        "    query_texts=query,\n",
        "    n_results=3\n",
        "    )\n",
        "\n",
        "  client.delete_collection(f\"gsds-{metric}\")\n",
        "\n",
        "  print(f'{metric}:', results['ids'][0], results['distances'][0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zb7M7u5htXbu"
      },
      "source": [
        "## 2. Implementing RAG With Langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3VKZfyHrngk",
        "outputId": "4ceb5650-20b0-4803-f3b8-618a54a3610f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bncAfe6eU6_r",
        "outputId": "adfe3893-c8af-4b72-d42b-fb725109d315"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:langchain_community.utils.user_agent:USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
          ]
        }
      ],
      "source": [
        "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
        "from langchain_chroma import Chroma\n",
        "\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "from langchain_core.vectorstores import InMemoryVectorStore\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.documents import Document\n",
        "\n",
        "from langchain_community.document_loaders import TextLoader, PyPDFLoader, AsyncHtmlLoader\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain_community.document_transformers import Html2TextTransformer\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "import io"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "wSH6sGLhh-us"
      },
      "outputs": [],
      "source": [
        "# vector_store.delete_collection()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t62bkYPyqZae"
      },
      "source": [
        "### 2-1. Load and Store the data from URL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aktC5G5-ucrp",
        "outputId": "47166183-d51a-4f22-9712-11949ac8be99"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Fetching pages:   0%|          | 0/1 [00:00<?, ?it/s]WARNING:langchain_community.document_loaders.async_html:Error fetching https://gsds.snu.ac.kr/academics/recruitment/ with attempt 1/3: Cannot connect to host gsds.snu.ac.kr:443 ssl:default [Connection reset by peer]. Retrying...\n",
            "Fetching pages: 100%|##########| 1/1 [00:04<00:00,  4.24s/it]\n"
          ]
        }
      ],
      "source": [
        "urls = [\"https://gsds.snu.ac.kr/academics/recruitment/\"]\n",
        "html = AsyncHtmlLoader(urls).load()\n",
        "\n",
        "html2text = Html2TextTransformer()\n",
        "\n",
        "docs_transformed = html2text.transform_documents(html)\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=60)\n",
        "docs_html = text_splitter.split_documents(docs_transformed)\n",
        "\n",
        "vector_store = Chroma.from_documents(docs_html, OpenAIEmbeddings(model='text-embedding-3-large', openai_api_key=OPENAI_API_KEY))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDrUaPpSqhLR"
      },
      "source": [
        "### 2-2. Load and Store the data from TXT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "mTIkVnrQkSdn",
        "outputId": "2e55d8e2-3401-4d78-df5e-0d23af28244b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['48b95005-81e0-4f07-a3aa-19ee95a91eed',\n",
              " '9e36c21a-c697-459b-9f46-fc1634ce39fd',\n",
              " '1b2ce8b6-bb9f-4dc5-a355-e84fcc885441',\n",
              " 'd9241ee2-3093-4696-bb2a-041f6e43e3ff',\n",
              " '1922a6b1-d73d-47a3-bdf1-8a4f35d62d71',\n",
              " 'd12da2cd-866b-4eb6-8549-7f064e20070a',\n",
              " '636b8b06-9807-4ae4-87cc-d1be5bb9e955',\n",
              " '3d535db1-0646-4baf-a949-817f79cd69e1',\n",
              " '9a6278c4-0c96-4148-8b53-1f6291bacaa6',\n",
              " 'b8527af0-4420-4129-866d-4d11049525fb',\n",
              " 'c92864a1-14cd-4ead-a52a-25e2341f193a',\n",
              " '5c14ce21-5b0c-4efa-b485-51ce7c5b86f7',\n",
              " '01e771d7-c496-4bfa-889c-58162181a34b',\n",
              " '99f96b59-e93e-455d-bde3-5386b8b32664',\n",
              " '2ce545d3-4c79-445c-9adc-39270a2807c6',\n",
              " '6ea65fdd-4fad-44ce-bd77-5bf57a85b30d',\n",
              " 'ea106867-2c52-4a3b-95fb-d7e9195a3e6f',\n",
              " '88bc0ca2-7c09-40c3-b67f-30c8e4361e46',\n",
              " 'db190982-af23-4a21-baf2-4edef7116f07',\n",
              " 'f25645c8-9bca-4328-b0b2-8dd30b3136cc',\n",
              " '40e392ac-2fea-4d2c-a6fa-13c22d36de24']"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "documents = TextLoader(\"./data/2024학년도 2학기 데이터사이언스대학원 석사학위 논문심사 계획 공고.txt\").load()\n",
        "# documents = PyPDFLoader(\"./data/2024학년도 2학기 데이터사이언스대학원 석사학위 논문심사 계획 공고.pdf\").load()\n",
        "docs = text_splitter.split_documents(documents)\n",
        "\n",
        "vector_store.add_documents(documents = docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_H912xibqqVG"
      },
      "source": [
        "### 2-3. Retrieval, Augmentation and Generation (RAG)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8c9lN6uiSJX",
        "outputId": "6a5d2ae3-9c47-4a90-9869-7f9f6495fdef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Answer: 박사 과정 신입학 모집 인원은 23명입니다 (출처: https://gsds.snu.ac.kr/academics/recruitment/).\n"
          ]
        }
      ],
      "source": [
        "# query = input('Question: ')\n",
        "query = '박사 과정 신입학 모집 인원은 몇 명이야?'\n",
        "retrieved_docs = vector_store.similarity_search(query, k=3)\n",
        "\n",
        "passages = \"\\n\".join([f\"Passage {i+1} (data_source: {doc.metadata['source']}):\\n{doc.page_content}\\n\" for i, doc in enumerate(retrieved_docs)])\n",
        "\n",
        "prompt_template = f\"\"\"\n",
        "# Question: {query}\n",
        "\n",
        "# Relevant Passages:\n",
        "{passages}\n",
        "\n",
        "# Based on the passages above, generate an answer to the question. Explicitly mention the 'data_source'.\n",
        "ex) (출처: gsds_notification.pdf)\n",
        "\"\"\"\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0, openai_api_key=OPENAI_API_KEY)\n",
        "prompt = PromptTemplate(template=prompt_template, input_variables=[\"query\", \"passages\"])\n",
        "\n",
        "chain = prompt | llm\n",
        "response = chain.invoke({\"query\": query, \"passages\": passages})\n",
        "\n",
        "print('Answer:', response.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-0z47IZvA8O"
      },
      "source": [
        "### 2-4. Run the RAG Chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RiE37O3XYW9K",
        "outputId": "bcddfcf3-53ca-489f-ae49-75567834549e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Type 'exit' to quit\n",
            "Enter a prompt: 학위 논문 제출 마감이 언제야?\n",
            "Answer: 학위 논문 제출 마감은 2025년 2월 3일(월) 24:00입니다. 이 기간 내에 학위논문을 제출해야 하며, 마감 이후에는 제출이나 수정이 불가합니다. 제출하지 않을 경우 학위를 받을 수 없습니다. (출처: ./data/2024학년도 2학기 데이터사이언스대학원 석사학위 논문심사 계획 공고.txt)\n",
            "Enter a prompt: '박사 과정 신입학 모집 인원은 몇 명이야?'\n",
            "Answer: 박사 과정 신입학 모집 인원은 23명입니다. (출처: https://gsds.snu.ac.kr/academics/recruitment/)\n",
            "Enter a prompt: exit\n",
            "Exiting...\n"
          ]
        }
      ],
      "source": [
        "def execute_chain():\n",
        "  print(\"Type 'exit' to quit\")\n",
        "  while True:\n",
        "    query = input(\"Enter a prompt: \")\n",
        "    if query.lower() == 'exit':\n",
        "      print('Exiting...')\n",
        "      break\n",
        "\n",
        "    else:\n",
        "      retrieved_docs = vector_store.similarity_search(query, k=5)\n",
        "      passages = \"\\n\".join([f\"Passage {i} (data_source: {doc.metadata['source']}):\\n{doc.page_content}\\n\" for i, doc in enumerate(retrieved_docs)])\n",
        "      prompt_template = f\"\"\"\n",
        "# Question: {query}\n",
        "\n",
        "# Relevant Passages:\n",
        "{passages}\n",
        "\n",
        "# Based on the passages above, generate an answer to the question. Explicitly mention the 'data_source'.\n",
        "ex) (출처: gsds_notification.pdf)\n",
        "\"\"\"\n",
        "      try:\n",
        "        llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0, openai_api_key=OPENAI_API_KEY)\n",
        "        prompt = PromptTemplate(template=prompt_template, input_variables=[\"query\", \"passages\"])\n",
        "        chain = prompt | llm\n",
        "        response = chain.invoke({\"query\": query, \"passages\": passages})\n",
        "        print('Answer:', response.content)\n",
        "\n",
        "      except Exception as e:\n",
        "          print(e)\n",
        "\n",
        "execute_chain()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
